---
layout: default
title: My MSc
lang: en
ref: master-track
---
<h2>MSc track</h2>

Compiling my activities as a MSc candidate in the Computer Science Department from the Institute of Mathematics and Statistics from the University of Sao Paulo.

<ul>
  <li><a href="#grade">Program work</a> </li>
  <li>
    <a href="#courses">Courses</a>
    <ol>
      
    </ol>
  </li>
  <li>
    <a href="#books">Books</a>
    <ol>
      <li>
      <a href="#book-of-why">The book of why</a>
      </li>      	      
    </ol>
    
  </li>

  <li>
    <a href="#presentations">My presentations</a>
    <ol>
      <li>
	<a href="#causal-may-2018">Causal Forests (May 2018)</a>
      </li>
      <li>
	<a href="#causal-may-2018">Causality, Causal Forests (March 2019)</a>
      </li>      	      
    </ol>    
  </li>
    
  <li>
    <a href="#papers">Papers</a>
    <ol>
      <li>
	Causal Inference in economics and marking:
	<a href="#varian-mkt"> summary</a>, <a href="http://ftp.cs.ucla.edu/pub/stat_ser/r481.pdf"> link </a>
      </li>
      
      <li>
	Data science is science's second chance to get causal inference right: A classification of data science tasks:
	<a href="#paper-do-seven-rules"> summary</a>, <a href="https://arxiv.org/abs/1804.10846"> link </a>
      </li>
	
      <li>
	Introduction to Judea Pearl's Do-Calculus: 
	<a href="#paper-do-calculus"> summary</a>, <a href="https://arxiv.org/abs/1305.5506"> link </a>
      </li>

      <li> The Seven Tools of Causal Inference with Reflections on Machine Learning:
	<a href="#paper-do-seven-rules"> summary</a>, <a href="http://ftp.cs.ucla.edu/pub/stat_ser/r481.pdf"> link </a>
      </li>

      <li>
	Limits of Estimating Heterogeneous Treatment Effects: Guidelines for Practical Algorithm Design:
	  <a href="#paper-limits-heterogeneous"> summary</a>, <a href="http://proceedings.mlr.press/v80/alaa18a.html"> link </a>
      </li>

      <li>
	  Machine Learning: An Applied Econometric Approach:
	  <a href="#applied-mullainathan"> summary</a>, <a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.31.2.87"> link </a>
      </li>

      <li>
	Humans Decisions and Machine Predictions: 
	<a href="#human-decisions"> summary</a>, <a href="https://cs.stanford.edu/~jure/pubs/bail-qje17.pdf"> link </a>
      </li>

      <li>
	Prediction Policy Problems:
	<a href="#prediction-policy-problems"> summary</a>, <a href="http://www.cs.cornell.edu/home/kleinber/aer15-prediction.pdf"> link </a>
      </li>

      <li> Estimations considerations in Contextual Bandits:
	<a href="#thompson-contextual-bandits"> summary</a>, <a href="https://arxiv.org/abs/1711.07077"> link </a>
      </li>
	    
      <li> Thompson Sampling for Contextual Bandits with Linear Payoffs:
	<a href="#thompson-contextual-bandits"> summary</a>, <a href="http://proceedings.mlr.press/v28/agrawal13.pdf"> link </a>
      </li>


      

    </ol>


  </li>
  <li>
    <a href="#books">People to follow</a>
    <ol>
      <li><a href="http://bayes.cs.ucla.edu/jp_home.html">Judea Pearl</a></li>
      <li> <a href="">Susan Athey</a></li>
      <li><a href="">Shalit</a></li>
      <li><a href="https://twitter.com/twiecki">Thomas Wiecki</a>, PyMC3 developer;</li>      
      <li><a href="http://web.stanford.edu/~swager/index.html">Stefan Wager</a></li>
      <li><a href="https://cc.ufc.br/curso/corpo-docente/carlos/">Carlos Brito</a></li>
    </ol>
    
  </li>

  <li>
    <a href="#software">Software/libraries to follow</a>
    <ol>
      <li><a href="http://causalinferenceinpython.org/">Python library causalinference</a></li>
    </ol>    
  </li>
  
  masterindex
  <li>
    <a href="#misc">Misc</a>
    <ol>
      <li>
	<a href="#pearl-curve-fitting">
	  To Build Truly Intelligent Machines, Teach Them Cause and Effect
	</a>
      </li>
	    
      <li>
	<a href="#beyond-curve-fitting">
	  ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus
	</a>
      </li>
      <li>
	<a href="#video-bernhard">
	  Toward Causal Machine Learning - Prof. Bernhard Schölkopf
	</a>
      </li>

      <li>
	A Linear “Microscope” for Interventions and Counterfactuals
	<a href="#linreg-causal"> summary</a>, <a href="http://ftp.cs.ucla.edu/pub/stat_ser/r459-reprint-errata.pdf"> link </a>
      </li>
      
      
    </ol>
  </li>
</ul>

<h3 id="grade">Program Work</h3>
<h3 id="courses">Courses</h3> 
<h3 id="books">Books</h3>
<ul>
  <li id="book-why">The book of why, Judea Pearl
    <div>
      I did a <a href="http://lgmoneda.github.io/2018/06/01/the-book-of-why.html">summary post</a> about it.
    </div>
  </li>    
</ul>

<h3 id="presentations">My presentations</h3>
<ul>
  <li id="causal-may-2018">
    A presentation about causal forests, <a href="../resources/causality_may_2018.pdf">slides</a>.
  </li>
  <li id="causal-may-2018">
    Liamf seminar, Data Science tasks, causality and the causal forest, <a href="../resources/Liamf - Causality and Causal Forest.pdf">slides</a>, <a href="../resources/Causal_Forest.ipynb">notebook</a>, <a href="../resources/causal_forest.R">R code</a>.
  </li>  
</ul>

<h3 id="others-presentations">Other's presentations</h3>
<ul>
  <li id="shalit">
    When and How Should One Use Deep Learning for Causal Effect Inference - Shalit, <a href="../resources/shalit.pdf">slides</a>.
  </li>

</ul>



<h3 id="papers">Papers</h3>
<ul>
  <li id="varian-mkt"><a href="http://www.pnas.org/content/pnas/113/27/7310.full.pdf">Causal Inference in economics and marketing</a>
    <div>
      Some techniques for causal inference. In causal inference, one should always be aware of the confounded variables, that is, a variable that influence both the treatment and the outcome.

<div align="center">
<figure>
	<a href="../../../images/master/causal-inference-identity.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/causal-inference-identity.png"/>
	</a>
	<figcaption>Causal Inference identity</figcaption>
</figure>
</div>      

      Experiments/Train-test-treat-compare (TTTC): Train a model using regular ML techniques (validation and so on). Then use it to predict the outcome of the varible o interest before the treatment date. The idea is to predict the outcome in a world without the treatment and then wait for the real outcome (the one in the presence of the treatment) and compare them.

<div align="center">
<figure>
	<a href="../../../images/master/tttc.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/tttc.png"/>
	</a>
	<figcaption>TTTC example</figcaption>
</figure>
</div>

</br></br>
Regression discontinuity: a common pratice to a policy is to define a threshold and apply different action for groups above and below it. Examples near this threshold are usually very similar and thus an experiment is created, because it's essentially random which side of the threshold a particular example ends up, specially if you're using models or just guessing a number (give credit for users above X score). Even better, you can add noise the the decision: if (score + e > threshold), do treatment. 

<div align="center">
<figure>
	<a href="../../../images/master/discontinuity.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/discontinuity.png"/>
	</a>
	<figcaption>Regression discontinuity example</figcaption>
</figure>
</div>
</br></br>

Instrumental Variables: trying to find a variable that is able to influence outcome but only via it's influence over a independent variable used to predict the outcome.
</br></br>

Difference in differences: you have two groups, treated and non-treated, and two time periods, before and after treatment. You can use the non-treated outcome to predict the counterfactual for the treated group.


<div align="center">
<figure>
	<a href="../../../images/master/diff-diff.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/diff-diff.png"/>
	</a>
	<figcaption>Difference in differences example</figcaption>
</figure>
</div>

</br></br>
    </div>
  </li>

  <li><a href="https://arxiv.org/abs/1804.10846">Data science is science's second chance to get causal inference right: A classification of data science tasks</a>
    <div>A cool trial to categorize data science tasks in three groups: description, prediction and causal inference.
</br></br>
      Description is for quantitative summary: computing proportions, mean, clustering and other visualizations.
      Prediction is the mapping of some inputs (X) to output(s) (y). It can be simple like quantifying the association between two variables and complex when using hundreds of features to predict a probability for a phenomena occurrence. So it goes from calculation the correlation coefficient to building models like random forests, neural networks and so on.
</br></br>
      Causal Inference is "using data to calculate certain feature of the world if the world had been different (that is, causal inference is counterfactual prediction)". An example would be the estimation of the mortality rate that would have been observed if all individuals in a study population had received screening for colorectal cancer versus if they had not received screening.
</br></br>
    Most of successful applications today in Data Science are merely predictive tasks. It happens because "a successful prediction only requires three elements: 1) a large dataset with inputs and outputs; 2) an algorithm that establishes a mapping between inputs and outputs; and 3) a metric to assess the performance of the mapping, often based on a gold standard.". After having the task defined and gathering the data, all the information required is in the data. No domain-specific knowledge is needed. 
</br></br>
      For causal inference the expert knowledge is needed, usually in the form of unverifiable causal assumptions. That is, even after specifying a well-defined causal task and acquiring relevant data, subject-matter knowledge is necessary to guide the data analysis and to provide a justification for endowing the result numerical  estimates with a causal interpretation. There's an example for health records database about maternal smoking during pregnancy and the risk of infant mortality. 

<div align="center">
<figure>
	<a href="../../../images/master/prediction-causal.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/prediction-causal.png"/>
	</a>
	<figcaption>Table from article</figcaption>
</figure>
</div>

      Randomly assigned treatment is a way of not relying on the expert knowledge to be able to estimate the average treatment effect. 
</br></br>
When the relevant expert knowledge can be easily encoded and incorporated into the algorithms the distinction between predictive and causal inference becomes unnecessary like in a Go playing system. It can easily computes the counterfactual of a play. 
</br></br>
      But most Auto "Most health and social scientists work with complex systems whose governing laws (the “rules of the game”) are not known in sufficient detail, it is unknown whether all necessary data are available, there is random error, and learning by trial and error is impossible."
</br></br>
    </div>
  </li>

  <!--Seven Rules -->

    <li id="paper-do-seven-rules"><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.31.2.87">The Seven Tools of Causal Inference with Reflections on Machine Learning, </a>
      <div>
	All the things that Structured Causal Models (SCM) can do. The tools described are:
	<ol>
	  <li>Encoding Causal Assumptions – Transparency and Testability: so being able to encode the assumptions accounts for transparency. Then being able to test then with available data makes it testable. Graphical models can provide both, using d-separation for testability. </li>
	  <li>Do -calculus and the control of confounding: using the back-door to block the paths and control for confounding. </li>
	  <li>The Algorithmization of Counterfactuals: with structural equation model, it's possible to analyze if a counterfactual question there can be answered using observational data, experimental data or both. </li>
	  <li>Mediation Analysis and the Assessment of Direct and Indirect Effects: it's about how the effects promote the cause. You can measure how much of the effect of X in Z is meadiated by Z, for example. </li>
	  <li>Adaptability, External Validity and Sample Selection Bias: this is very nice I'm going to have to copy and paste:
	    "The validity of every experimental study is challenged by disparities
	    between the experimental and implementational setups. A machine
	    trained in one environment cannot be expected to perform well
	    when environmental conditions change, unless the changes are
	    localized and identified. This problem, and its various manifesta-
	    tions are well recognized by AI researchers, and enterprises such
	    as “domain adaptation,” “transfer learning,” “life-long learning,” and
	    “explainable AI” [Chen and Liu 2016], are just some of the subtasks
	    identified by researchers and funding agencies in an attempt to alle-
	    viate the general problem of robustness. Unfortunately, the problem
	    of robustness, in its broadest form, requires a causal model of the
	    environment, and cannot be handled at the level of Association.
	    Associations are not sufficient for identifying the mechanisms affected
	    by changes that occurred [Pearl and Bareinboim 2014]. The reason
	    being that surface changes in observed associations do not uniquely
	    identify the underlying mechanism responsible for the change. The
	    do
	    -calculus discussed above now offers a complete methodology
	    for overcoming bias due to environmental changes. It can be used
	    both for re-adjusting learned policies to circumvent environmental
	    changes and for controlling bias due to non-representative samples
	    [Bareinboim and Pearl 2016]."
	  </li>
	  <li> Recovering from Missing Data: when the missing in our data is not random, you better go causal. </li>
	  <li>Causal Discovery: when you're trying to define the right graphical model, you can use techniques to test the candidates and discover/test the causal relation there.</li>	  
	</ol>
	At conclusion:
	"It is also important to keep in mind that the theoretical limitations
	of model-free machine learning do not apply to tasks of prediction,
	diagnosis and recognition, where interventions and counterfactuals
	assume a secondary role."
      </div>
  </li>

    <!--Seven Rules -->
    
  <li id="applied-mullainathan"><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.31.2.87">Machine Learning: An applied Econometric Approach</a>
    <div>
      Critic about the misusage of Machine Learning techniques for estimation purposes. A cool example about Lasso, that picks different variables in each fold: how could I interpret model parameters with different folds with similar predictive power present very different structure? The author points as ML weakness the absent of strong and mostly unverifiable assumptions, as ML does not produce stable estimates of the underlying parameters. And points as its strength the predictive power that is useful for "$\hat{y}$ problems": new data (text and images), prediction in the service of estimation (use for linear instrumental variable), prediction for policies (the judge example) and testing theories about predictability (can this info from the past be used to predict this future outcome?).
<div align="center">
<figure>
	<a href="../../../images/master/lasso.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/lasso.png"/>
	</a>
	<figcaption>Lasso coefficients are unstable across different folds.</figcaption>
</figure>
</div>      

    </div>
  </li>

  <!-- End -->

  <!--Begin  -->

  <li id="paper-do-seven-rules"><a href="https://pubs.aeaweb.org/doi/pdfplus/10.1257/jep.31.2.87">Estimation Considerations in Contextual Bandits, </a>
    <div>
      A discussion/guidance for how to choose between contextual bandits algorithms alternatives accordingly with your application, considering the problems that arise from the choosen function to learn the outcome given the covariates and biased data considering the learning early stage. Long history short: IPW (inverse probability weighting) helps when you have a "bad" start with biased data, it makes the contextual bandit explore that region and don't abandon it early. Also, Thompson Sampling, a randomized way to assign treatments, is better to deal with bias data and misspecified potential outcome model.
    </div>
  </li>

  <!-- End -->

  <!--Begin  -->

  <li id="prediction-policy-problems"><a href="http://www.cs.cornell.edu/home/kleinber/aer15-prediction.pdf"> Prediction Problem Policies  </a>
    <div>
      A cool discussion about policies that can be build on top of pure predictive models (instead of causal ones). It states the problem with the equation:

      $$\frac{d\pi(X_{0}, Y)}{dX_{0}} = \frac{\partial \pi}{\partial X_{0}} (Y) + \frac{\partial \pi}{\partial Y} \frac{\partial Y}{\partial X_{0}} $$

      Where the \(\pi\) is the pay-off function, \(X_{0} \) is the decision one can take and \(Y\) is the outcome of the matter of study. So the first argument is about how the pay-off respond to our decision considering the \(Y\), so it depends on \(Y\) so predicting \(Y\) correctly is the important thing here. The second argument is how \(X_{0} \) impacts \(Y\) and then how this change will impact on \(\pi\).

      The paper example about pure predictive is about a rain dance and takin an umbrella. So for someone that wants to make it rain, it's important that the rain dance causes rain and the pay-off depends on the second part (how much rain dance can influence rain). If you want to decide about taking and umbrella to work, the payoff depends on the fact that it may rain or not, and it's also known that takin an umbrella or not cannot influence rain, so the first argument is the important part and the second is zero. The real-life example is the knee surgery for elderly people, the benefit \(\pi\) depends on the prediction about how many years the person will live to take advantage of the surgery. So predicting it right is the only thing needed to make a good policy, so it can be built upon a purely predictive model.
    </div>
  </li>

  <!-- End -->

     
</ul>

<h3 id="misc">Misc</h3>
<ol>
  <li>
      <h4 id="pearl-curve-fitting"><a href="https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/"> To Build Truly Intelligent Machines, Teach Them Cause and Effect</a> </h4>
  <div>
    The cool interview in which Pearl claims: “All the impressive achievements of deep learning amount to just curve fitting...”.
  </div>  
  </li>

<li>
  <h4 id="beyond-curve-fitting"><a href="http://www.inference.vc/untitled/"> ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus</a> </h4>
  <div>
    Nice blog post with an introduction to the causal think. It's mostly about the setup of a causal question instead of a prediction one. It has nice images about the causality representation. 
  </div>  
</li>

<li>
  <h4 id="video-bernhard"><a href="https://www.youtube.com/watch?v=ooeRlw3U2zU"> Toward Causal Machine Learning - Prof. Bernhard Schölkopf</a> </h4>
  <div>

  </div>  
</li>
</ol>
