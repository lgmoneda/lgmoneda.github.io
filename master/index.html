---
layout: default
title: My MSc
lang: en
ref: master-track
---
<h2>MSc track</h2>

Compiling my activities as a MSc candidate in the Computer Science Department from the Institute of Mathematics and Statistics from the University of Sao Paulo.

<ul>
  <li><a href="#grade">Program work</a> </li>
  <li>
    <a href="#courses">Courses</a>
    <ol>
      
    </ol>
  </li>
  <li>
    <a href="#books">Books</a>
    <ol>
      <li>
      <a href="#book-of-why">The book of why</a>
      </li>      	      
    </ol>
    
  </li>

  <li>
    <a href="#books">My presentations</a>
    <ol>
      <li>
	<a href="#causal-may-2018">Causal Forests (May 2018)</a>
      </li>      	      
    </ol>    
  </li>
    
  <li>
    <a href="#papers">Papers</a>
    <ol>
      <li>
      <a href="#varian-mkt">Causal Inference in eocnomics and marking</a>
      </li>
      
      <li>
	<a href="https://arxiv.org/abs/1804.10846">Data science is science's second chance to get causal inference right: A classification of data science tasks</a>
      </li>
	
      <li>
	<a href="#paper-do-calculus">
	  Introduction to Judea Pearl's Do-Calculus (https://arxiv.org/abs/1305.5506)
	</a>
      </li>
      
    </ol>
    
  </li>
  <li>
    <a href="#books">People to follow</a>
    <ol>
      <li>
	<a href="">Susan Athey</a>
	<a href="">Shalit</a>
	<a href="http://web.stanford.edu/~swager/index.html">Stefan Wager</a>
      </li>      	      
    </ol>
    
  </li>
  <li>
    <a href="#misc">Misc</a>
    <ol>
      <li>
	<a href="#pearl-curve-fitting">
	  To Build Truly Intelligent Machines, Teach Them Cause and Effect
	</a>
      </li>
	    
      <li>
	<a href="#beyond-curve-fitting">
	  ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus
	</a>
      </li>
      <li>
	<a href="#video-bernhard">
	  Toward Causal Machine Learning - Prof. Bernhard Schölkopf
	</a>
      </li>
    </ol>
  </li>
</ul>

<h3 id="grade">Program Work</h3>
<h3 id="courses">Courses</h3> 
<h3 id="books">Books</h3>
<ul>
  <li id="book-why">The book of why, Judea Pearl
    <div>
      I did a <a href="http://lgmoneda.github.io/2018/06/01/the-book-of-why.html">summary post</a> about it.
    </div>
  </li>    
</ul>

<h3 id="presentations">My presentations</h3>
<ul>
  <li id="causal-may-2018">
    A presentation about causal forests, <a href="../resources/causality_may_2018.pdf">slides</a>.
  </li>

</ul>

<h3 id="others-presentations">Other's presentations</h3>
<ul>
  <li id="shalit">
    When and How Should One Use Deep Learning for Causal Effect Inference - Shalit, <a href="../resources/shalit.pdf">slides</a>.
  </li>

</ul>



<h3 id="papers">Papers</h3>
<ul>
  <li id="varian-mkt"><a href="http://www.pnas.org/content/pnas/113/27/7310.full.pdf">Causal Inference in economics and marketing</a>
    <div>
      Some techniques for causal inference. In causal inference, one should always be aware of the confounded variables, that is, a variable that influence both the treatment and the outcome.

<div align="center">
<figure>
	<a href="../../../images/master/causal-inference-identity.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/causal-inference-identity.png"/>
	</a>
	<figcaption>Causal Inference identity</figcaption>
</figure>
</div>      

      Experiments/Train-test-treat-compare (TTTC): Train a model using regular ML techniques (validation and so on). Then use it to predict the outcome of the varible o interest before the treatment date. The idea is to predict the outcome in a world without the treatment and then wait for the real outcome (the one in the presence of the treatment) and compare them.

<div align="center">
<figure>
	<a href="../../../images/master/tttc.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/tttc.png"/>
	</a>
	<figcaption>TTTC example</figcaption>
</figure>
</div>

</br></br>
Regression discontinuity: a common pratice to a policy is to define a threshold and apply different action for groups above and below it. Examples near this threshold are usually very similar and thus an experiment is created, because it's essentially random which side of the threshold a particular example ends up, specially if you're using models or just guessing a number (give credit for users above X score). Even better, you can add noise the the decision: "if (score + e > threshold), do treatment". 

<div align="center">
<figure>
	<a href="../../../images/master/discontinuity.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/discontinuity.png"/>
	</a>
	<figcaption>Regression discontinuity example</figcaption>
</figure>
</div>
</br></br>

Instrumental Variables: trying to find a variable that is able to influence outcome but only via it's influence over a independent variable used to predict the outcome.
</br></br>

Difference in differences: you have two groups, treated and non-treated, and two time periods, before and after treatment. You can use the non-treated outcome to predict the counterfactual for the treated group.


<div align="center">
<figure>
	<a href="../../../images/master/diff-diff.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/diff-diff.png"/>
	</a>
	<figcaption>Difference in differences example</figcaption>
</figure>
</div>

</br></br>
    </div>
  </li>

  <li><a href="https://arxiv.org/abs/1804.10846">Data science is science's second chance to get causal inference right: A classification of data science tasks</a>
    <div>A cool trial to categorize data science tasks in three groups: description, prediction and causal inference.
</br></br>
      Description is for quantitative summary: computing proportions, mean, clustering and other visualizations.
      Prediction is the mapping of some inputs (X) to output(s) (y). It can be simple like quantifying the association between two variables and complex when using hundreds of features to predict a probability for a phenomena occurrence. So it goes from calculation the correlation coefficient to building models like random forests, neural networks and so on.
</br></br>
      Causal Inference is "using data to calculate certain feature of the world if the world had been different (that is, causal inference is counterfactual prediction)". An example would be the estimation of the mortality rate that would have been observed if all individuals in a study population had received screening for colorectal cancer versus if they had not received screening.
</br></br>
    Most of successful applications today in Data Science are merely predictive tasks. It happens because "a successful prediction only requires three elements: 1) a large dataset with inputs and outputs; 2) an algorithm that establishes a mapping between inputs and outputs; and 3) a metric to assess the performance of the mapping, often based on a gold standard.". After having the task defined and gathering the data, all the information required is in the data. No domain-specific knowledge is needed. 
</br></br>
      For causal inference the expert knowledge is needed, usually in the form of unverifiable causal assumptions. That is, even after specifying a well-defined causal task and acquiring relevant data, subject-matter knowledge is necessary to guide the data analysis and to provide a justification for endowing the result numerical  estimates with a causal interpretation. There's an example for health records database about maternal smoking during pregnancy and the risk of infant mortality. 

<div align="center">
<figure>
	<a href="../../../images/master/prediction-causal.png">
		<img  style="width:450px;margin:10px" src="../../../images/master/prediction-causal.png"/>
	</a>
	<figcaption>Table from article</figcaption>
</figure>
</div>

      Randomly assigned treatment is a way of not relying on the expert knowledge to be able to estimate the average treatment effect. 
</br></br>
When the relevant expert knowledge can be easily encoded and incorporated into the algorithms the distinction between predictive and causal inference becomes unnecessary like in a Go playing system. It can easily computes the counterfactual of a play. 
</br></br>
      But most Auto "Most health and social scientists work with complex systems whose governing laws (the “rules of the game”) are not known in sufficient detail, it is unknown whether all necessary data are available, there is random error, and learning by trial and error is impossible."
</br></br>
    </div>
  </li>
</ul>

<h3 id="misc">Misc</h3>
<ol>
  <li>
      <h4 id="pearl-curve-fitting"><a href="https://www.quantamagazine.org/to-build-truly-intelligent-machines-teach-them-cause-and-effect-20180515/"> To Build Truly Intelligent Machines, Teach Them Cause and Effect</a> </h4>
  <div>
    The cool interview in which Pearl claims: “All the impressive achievements of deep learning amount to just curve fitting...”.
  </div>  
  </li>

<li>
  <h4 id="beyond-curve-fitting"><a href="http://www.inference.vc/untitled/"> ML beyond Curve Fitting: An Intro to Causal Inference and do-Calculus</a> </h4>
  <div>
    Nice blog post with an introduction to the causal think. It's mostly about the setup of a causal question instead of a prediction one. It has nice images about the causality representation. 
  </div>  
</li>

<li>
  <h4 id="video-bernhard"><a href="https://www.youtube.com/watch?v=ooeRlw3U2zU"> Toward Causal Machine Learning - Prof. Bernhard Schölkopf</a> </h4>
  <div>

  </div>  
</li>

</ol>
